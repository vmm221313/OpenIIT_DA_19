{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as po\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import ensemble, tree, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = po.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Customer Lifetime Value</th>\n",
       "      <th>Response</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Education</th>\n",
       "      <th>EmploymentStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Location Code</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Months Since Policy Inception</th>\n",
       "      <th>Number of Open Complaints</th>\n",
       "      <th>Number of Policies</th>\n",
       "      <th>Policy Type</th>\n",
       "      <th>Policy</th>\n",
       "      <th>Renew Offer Type</th>\n",
       "      <th>Sales Channel</th>\n",
       "      <th>Total Claim Amount</th>\n",
       "      <th>Vehicle Class</th>\n",
       "      <th>Vehicle Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington</td>\n",
       "      <td>2763.519279</td>\n",
       "      <td>No</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>56274</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L3</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Agent</td>\n",
       "      <td>384.811147</td>\n",
       "      <td>Two-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>6979.535903</td>\n",
       "      <td>No</td>\n",
       "      <td>Extended</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Offer3</td>\n",
       "      <td>Agent</td>\n",
       "      <td>1131.464935</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>12887.431650</td>\n",
       "      <td>No</td>\n",
       "      <td>Premium</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Employed</td>\n",
       "      <td>F</td>\n",
       "      <td>48767</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L3</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Agent</td>\n",
       "      <td>566.472247</td>\n",
       "      <td>Two-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>California</td>\n",
       "      <td>7645.861827</td>\n",
       "      <td>No</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Suburban</td>\n",
       "      <td>Married</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Corporate Auto</td>\n",
       "      <td>Corporate L2</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Call Center</td>\n",
       "      <td>529.881344</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Washington</td>\n",
       "      <td>2813.692575</td>\n",
       "      <td>No</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Employed</td>\n",
       "      <td>M</td>\n",
       "      <td>43836</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Single</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Personal Auto</td>\n",
       "      <td>Personal L1</td>\n",
       "      <td>Offer1</td>\n",
       "      <td>Agent</td>\n",
       "      <td>138.130879</td>\n",
       "      <td>Four-Door Car</td>\n",
       "      <td>Medsize</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        State  Customer Lifetime Value Response  Coverage Education  \\\n",
       "0  Washington              2763.519279       No     Basic  Bachelor   \n",
       "1     Arizona              6979.535903       No  Extended  Bachelor   \n",
       "2      Nevada             12887.431650       No   Premium  Bachelor   \n",
       "3  California              7645.861827       No     Basic  Bachelor   \n",
       "4  Washington              2813.692575       No     Basic  Bachelor   \n",
       "\n",
       "  EmploymentStatus Gender  Income Location Code Marital Status  ...  \\\n",
       "0         Employed      F   56274      Suburban        Married  ...   \n",
       "1       Unemployed      F       0      Suburban         Single  ...   \n",
       "2         Employed      F   48767      Suburban        Married  ...   \n",
       "3       Unemployed      M       0      Suburban        Married  ...   \n",
       "4         Employed      M   43836         Rural         Single  ...   \n",
       "\n",
       "   Months Since Policy Inception  Number of Open Complaints  \\\n",
       "0                              5                          0   \n",
       "1                             42                          0   \n",
       "2                             38                          0   \n",
       "3                             65                          0   \n",
       "4                             44                          0   \n",
       "\n",
       "   Number of Policies     Policy Type        Policy Renew Offer Type  \\\n",
       "0                   1  Corporate Auto  Corporate L3           Offer1   \n",
       "1                   8   Personal Auto   Personal L3           Offer3   \n",
       "2                   2   Personal Auto   Personal L3           Offer1   \n",
       "3                   7  Corporate Auto  Corporate L2           Offer1   \n",
       "4                   1   Personal Auto   Personal L1           Offer1   \n",
       "\n",
       "  Sales Channel Total Claim Amount  Vehicle Class  Vehicle Size  \n",
       "0         Agent         384.811147   Two-Door Car       Medsize  \n",
       "1         Agent        1131.464935  Four-Door Car       Medsize  \n",
       "2         Agent         566.472247   Two-Door Car       Medsize  \n",
       "3   Call Center         529.881344            SUV       Medsize  \n",
       "4         Agent         138.130879  Four-Door Car       Medsize  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figure out if we gen extract something from this number, till then drop\n",
    "date_col = train['Effective To Date']\n",
    "train = train.drop(['Customer', 'Effective To Date'], axis = 1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = po.get_dummies(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Customer Lifetime Value           float64\n",
       "Income                              int64\n",
       "Monthly Premium Auto                int64\n",
       "Months Since Last Claim             int64\n",
       "Months Since Policy Inception       int64\n",
       "Number of Open Complaints           int64\n",
       "Number of Policies                  int64\n",
       "Total Claim Amount                float64\n",
       "State_Arizona                       uint8\n",
       "State_California                    uint8\n",
       "State_Nevada                        uint8\n",
       "State_Oregon                        uint8\n",
       "State_Washington                    uint8\n",
       "Response_No                         uint8\n",
       "Response_Yes                        uint8\n",
       "Coverage_Basic                      uint8\n",
       "Coverage_Extended                   uint8\n",
       "Coverage_Premium                    uint8\n",
       "Education_Bachelor                  uint8\n",
       "Education_College                   uint8\n",
       "Education_Doctor                    uint8\n",
       "Education_High School or Below      uint8\n",
       "Education_Master                    uint8\n",
       "EmploymentStatus_Disabled           uint8\n",
       "EmploymentStatus_Employed           uint8\n",
       "EmploymentStatus_Medical Leave      uint8\n",
       "EmploymentStatus_Retired            uint8\n",
       "EmploymentStatus_Unemployed         uint8\n",
       "Gender_F                            uint8\n",
       "Gender_M                            uint8\n",
       "                                   ...   \n",
       "Marital Status_Single               uint8\n",
       "Policy Type_Corporate Auto          uint8\n",
       "Policy Type_Personal Auto           uint8\n",
       "Policy Type_Special Auto            uint8\n",
       "Policy_Corporate L1                 uint8\n",
       "Policy_Corporate L2                 uint8\n",
       "Policy_Corporate L3                 uint8\n",
       "Policy_Personal L1                  uint8\n",
       "Policy_Personal L2                  uint8\n",
       "Policy_Personal L3                  uint8\n",
       "Policy_Special L1                   uint8\n",
       "Policy_Special L2                   uint8\n",
       "Policy_Special L3                   uint8\n",
       "Renew Offer Type_Offer1             uint8\n",
       "Renew Offer Type_Offer2             uint8\n",
       "Renew Offer Type_Offer3             uint8\n",
       "Renew Offer Type_Offer4             uint8\n",
       "Sales Channel_Agent                 uint8\n",
       "Sales Channel_Branch                uint8\n",
       "Sales Channel_Call Center           uint8\n",
       "Sales Channel_Web                   uint8\n",
       "Vehicle Class_Four-Door Car         uint8\n",
       "Vehicle Class_Luxury Car            uint8\n",
       "Vehicle Class_Luxury SUV            uint8\n",
       "Vehicle Class_SUV                   uint8\n",
       "Vehicle Class_Sports Car            uint8\n",
       "Vehicle Class_Two-Door Car          uint8\n",
       "Vehicle Size_Large                  uint8\n",
       "Vehicle Size_Medsize                uint8\n",
       "Vehicle Size_Small                  uint8\n",
       "Length: 65, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 7431, 1: 1703})\n",
      "Counter({0: 5984, 1: 3150})\n",
      "Counter({0: 8252, 1: 882})\n",
      "Counter({0: 6533, 1: 2601})\n",
      "Counter({0: 8336, 1: 798})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(train['State_Arizona']))\n",
    "print(Counter(train['State_California']))\n",
    "print(Counter(train['State_Nevada']))\n",
    "print(Counter(train['State_Oregon']))\n",
    "print(Counter(train['State_Washington']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('Customer Lifetime Value', axis = 1)\n",
    "y = train['Customer Lifetime Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(estimator, x_trn, x_tst, y_trn, y_tst):\n",
    "    prediction_train = estimator.predict(x_trn)\n",
    "    # Printing estimator\n",
    "    #print(estimator)\n",
    "    # Printing train scores\n",
    "    #get_score(prediction_train, y_trn)\n",
    "    prediction_test = estimator.predict(x_tst)\n",
    "    # Printing test scores\n",
    "    #print(\"Test\")\n",
    "    #get_score(prediction_test, y_tst)\n",
    "    return {\n",
    "        'r2' : r2_score(prediction_test, y_tst), \n",
    "        'RMSE' : np.sqrt(mean_squared_error(prediction_test, y_tst))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBoost = ensemble.GradientBoostingRegressor(n_estimators=10, learning_rate=1, max_depth=3, max_features='sqrt', min_samples_leaf=15, min_samples_split=20, loss='huber').fit(X_train, y_train)\n",
    "t = train_test(GBoost, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7726538814612314"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 9/150 [11:57<3:20:22, 85.27s/it, best loss: 4195.434590250059] "
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin,tpe,hp, STATUS_OK\n",
    "min_rmse = 10000000\n",
    "def f(space):\n",
    "    \n",
    "    global best_nest, best_lr, best_m_d, min_rmse\n",
    "    nest = space['nest']\n",
    "    lr = space['lr']/100\n",
    "    m_d = space['m_d']\n",
    "    \n",
    "    GBoost = ensemble.GradientBoostingRegressor(n_estimators=int(nest), learning_rate=lr, max_depth=int(m_d), max_features='sqrt', min_samples_leaf=15, min_samples_split=20, loss='huber').fit(X_train, y_train)\n",
    "    results = train_test(GBoost, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    rmse = results['RMSE']\n",
    "    if (rmse < min_rmse):\n",
    "        min_rmse = rmse\n",
    "        best_nest = nest\n",
    "        best_lr = lr\n",
    "        best_m_d = m_d\n",
    "    \n",
    "    return {'loss': rmse, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'nest': hp.quniform('nest', 1000, 5000,1000),\n",
    "    'lr': hp.quniform('lr',1,5,1),\n",
    "    'm_d': hp.quniform('i',5,20,5)\n",
    "    }\n",
    "\n",
    "best = fmin(fn=f,space=space,algo=tpe.suggest,max_evals=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "model = MLPRegressor(random_state = 42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44847804.614618815"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66274162397.240395, tolerance: 17537174.15294648\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67261129390.33797, tolerance: 18549801.716804035\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 64253591690.527245, tolerance: 18613250.942386128\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50655179089.56981, tolerance: 17537174.15294648\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46871137550.23158, tolerance: 18549801.716804035\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43756103275.11551, tolerance: 18613250.942386128\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61096479039.73454, tolerance: 17537174.15294648\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60448484740.665855, tolerance: 18549801.716804035\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 59906116785.94881, tolerance: 18613250.942386128\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40273908.82867432, tolerance: 17537174.15294648\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4488434588.58577, tolerance: 17537174.15294648\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35286801850.153114, tolerance: 17537174.15294648\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54465685.32714844, tolerance: 18549801.716804035\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2739125081.9310303, tolerance: 18549801.716804035\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28614523838.01938, tolerance: 18549801.716804035\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28794736.78250122, tolerance: 18613250.942386128\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2628251895.041397, tolerance: 18613250.942386128\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28637901035.043365, tolerance: 18613250.942386128\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5404548549.676315, tolerance: 18549801.716804035\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1880876219.8426971, tolerance: 18549801.716804035\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2065723353.9656525, tolerance: 18549801.716804035\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5492688678.176086, tolerance: 18613250.942386128\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 10], copy_X=True,\n",
      "             cv='warn', eps=0.001, fit_intercept=True,\n",
      "             l1_ratio=[0.01, 0.1, 0.5, 0.9, 0.99], max_iter=5000, n_alphas=100,\n",
      "             n_jobs=None, normalize=False, positive=False, precompute='auto',\n",
      "             random_state=None, selection='cyclic', tol=0.0001, verbose=0)\n",
      "R2: -4.155560862783326\n",
      "RMSE: 6103.744413448481\n",
      "Test\n",
      "R2: -5.1403290869788965\n",
      "RMSE: 6615.996744233475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1807760270.9194489, tolerance: 18613250.942386128\n",
      "  tol, rng, random, positive)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1987799491.5413666, tolerance: 18613250.942386128\n",
      "  tol, rng, random, positive)\n"
     ]
    }
   ],
   "source": [
    "ENSTest = linear_model.ElasticNetCV(alphas=[0.0001, 0.0005, 0.001, 0.01, 0.1, 1, 10], l1_ratio=[.01, .1, .5, .9, .99], max_iter=5000).fit(X_train, y_train)\n",
    "train_test(ENSTest, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='huber', max_depth=10,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=20, min_samples_split=20,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=10000,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "R2: 0.8217828959104783\n",
      "RMSE: 2265.1636383670657\n",
      "Test\n",
      "R2: 0.30140017577535094\n",
      "RMSE: 4183.705261364222\n"
     ]
    }
   ],
   "source": [
    "GBest = ensemble.GradientBoostingRegressor(n_estimators=10000, learning_rate=0.05, max_depth=10, max_features='sqrt',\n",
    "                                               min_samples_leaf=20, min_samples_split=20, loss='huber').fit(X_train, y_train)\n",
    "\n",
    "train_test(GBest, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(pipeline, parameters, X_train, y_train, X, y):\n",
    "\n",
    "    grid_obj = GridSearchCV(estimator=pipeline,\n",
    "                            param_grid=parameters,\n",
    "                            cv=3,\n",
    "                            scoring='r2',\n",
    "                            verbose=2,\n",
    "                            n_jobs=1,\n",
    "                            refit=True)\n",
    "    grid_obj.fit(X_train, y_train)\n",
    "\n",
    "    '''Results'''\n",
    "\n",
    "    results = pd.DataFrame(pd.DataFrame(grid_obj.cv_results_))\n",
    "    results_sorted = results.sort_values(by=['mean_test_score'], ascending=False)\n",
    "\n",
    "    print(\"##### Results\")\n",
    "    print(results_sorted)\n",
    "\n",
    "    print(\"best_index\", grid_obj.best_index_)\n",
    "    print(\"best_score\", grid_obj.best_score_)\n",
    "    print(\"best_params\", grid_obj.best_params_)\n",
    "\n",
    "    '''Cross Validation'''\n",
    "\n",
    "    estimator = grid_obj.best_estimator_\n",
    "    '''\n",
    "    if estimator.named_steps['scl'] == True:\n",
    "        X = (X - X.mean()) / (X.std())\n",
    "        y = (y - y.mean()) / (y.std())\n",
    "    '''\n",
    "    shuffle = KFold(n_splits=5,\n",
    "                    shuffle=True,\n",
    "                    random_state=0)\n",
    "    cv_scores = cross_val_score(estimator,\n",
    "                                X,\n",
    "                                y.values.ravel(),\n",
    "                                cv=shuffle,\n",
    "                                scoring='r2')\n",
    "    print(\"##### CV Results\")\n",
    "    print(\"mean_score\", cv_scores.mean())\n",
    "\n",
    "    '''Show model coefficients or feature importances'''\n",
    "\n",
    "    try:\n",
    "        print(\"Model coefficients: \", list(zip(list(X), estimator.named_steps['clf'].coef_)))\n",
    "    except:\n",
    "        print(\"Model does not support model coefficients\")\n",
    "\n",
    "    try:\n",
    "        print(\"Feature importances: \", list(zip(list(X), estimator.named_steps['clf'].feature_importances_)))\n",
    "    except:\n",
    "        print(\"Model does not support feature importances\")\n",
    "\n",
    "    '''Predict along CV and plot y vs. y_predicted in scatter'''\n",
    "\n",
    "    y_pred = cross_val_predict(estimator, X, y, cv=shuffle)\n",
    "\n",
    "    plt.scatter(y, y_pred)\n",
    "    xmin, xmax = plt.xlim()\n",
    "    ymin, ymax = plt.ylim()\n",
    "    plt.plot([xmin, xmax], [ymin, ymax], \"g--\", lw=1, alpha=0.4)\n",
    "    plt.xlabel(\"True prices\")\n",
    "    plt.ylabel(\"Predicted prices\")\n",
    "    plt.annotate(' R-squared CV = {}'.format(round(float(cv_scores.mean()), 3)), size=9,\n",
    "             xy=(xmin,ymax), xytext=(10, -15), textcoords='offset points')\n",
    "    plt.annotate(grid_obj.best_params_, size=9,\n",
    "                 xy=(xmin, ymax), xytext=(10, -35), textcoords='offset points', wrap=True)\n",
    "    plt.title('Predicted prices (EUR) vs. True prices (EUR)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eda = po.read_csv('train.csv')\n",
    "import pandas_profiling\n",
    "profile = train_eda.profile_report(title='Pandas Profiling Report')\n",
    "profile.to_file(output_file=\"EDA.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['Income','Monthly_Premium_Auto','Number_of_Open_Complaints','Number_of_Policies','Total_Claim_Amount']]\n",
    "y = train['Customer_Lifetime_Value']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='huber', max_depth=15,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=20,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=10000,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "R2: 0.8783425630519581\n",
      "RMSE: 1941.669852539646\n",
      "Test\n",
      "R2: 0.3330891963353585\n",
      "RMSE: 4116.924000036346\n"
     ]
    }
   ],
   "source": [
    "GBest = ensemble.GradientBoostingRegressor(n_estimators=10000, learning_rate=0.05, max_depth=15, max_features='sqrt',\n",
    "                                               min_samples_leaf=15, min_samples_split=20, loss='huber').fit(X_train, y_train)\n",
    "\n",
    "train_test(GBest, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "                          learning_rate=0.05, loss='huber', max_depth=5,\n",
      "                          max_features='sqrt', max_leaf_nodes=None,\n",
      "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                          min_samples_leaf=15, min_samples_split=20,\n",
      "                          min_weight_fraction_leaf=0.0, n_estimators=10000,\n",
      "                          n_iter_no_change=None, presort='auto',\n",
      "                          random_state=None, subsample=1.0, tol=0.0001,\n",
      "                          validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "R2: 0.6748245709239471\n",
      "RMSE: 2851.9726975884687\n",
      "Test\n",
      "R2: 0.2044805036990821\n",
      "RMSE: 4266.960298705104\n"
     ]
    }
   ],
   "source": [
    "RF = ensemble.RandomForestRegressor().fit(X_train, y_train)\n",
    "train_test(GBest, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "model = MLPRegressor(random_state = 42).fit(X_train, y_train)\n",
    "train_test(model, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = po.read_csv('train.csv')\n",
    "train = po.get_dummies(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[['Income','Monthly Premium Auto','Number of Open Complaints','Number of Policies','Total Claim Amount']]\n",
    "y = train['Customer Lifetime Value']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "num_epochs = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(in_features = len(X.columns), out_features = 1)\n",
    "model = model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = po.DataFrame(y_train)\n",
    "y_train.columns = [0]\n",
    "y_train = y_train.reset_index()\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    output = model(torch.tensor(X_train.to_numpy()).double())\n",
    "    loss = criterion(output,torch.tensor(y_train.to_numpy()).long())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 10000 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Customer Lifetime Value', 'Income', 'Monthly Premium Auto',\n",
       "       'Months Since Last Claim', 'Months Since Policy Inception',\n",
       "       'Number of Open Complaints', 'Number of Policies', 'Total Claim Amount',\n",
       "       'State_Arizona', 'State_California', 'State_Nevada', 'State_Oregon',\n",
       "       'State_Washington', 'Response_No', 'Response_Yes', 'Coverage_Basic',\n",
       "       'Coverage_Extended', 'Coverage_Premium', 'Education_Bachelor',\n",
       "       'Education_College', 'Education_Doctor',\n",
       "       'Education_High School or Below', 'Education_Master',\n",
       "       'EmploymentStatus_Disabled', 'EmploymentStatus_Employed',\n",
       "       'EmploymentStatus_Medical Leave', 'EmploymentStatus_Retired',\n",
       "       'EmploymentStatus_Unemployed', 'Gender_F', 'Gender_M',\n",
       "       'Location Code_Rural', 'Location Code_Suburban', 'Location Code_Urban',\n",
       "       'Marital Status_Divorced', 'Marital Status_Married',\n",
       "       'Marital Status_Single', 'Policy Type_Corporate Auto',\n",
       "       'Policy Type_Personal Auto', 'Policy Type_Special Auto',\n",
       "       'Policy_Corporate L1', 'Policy_Corporate L2', 'Policy_Corporate L3',\n",
       "       'Policy_Personal L1', 'Policy_Personal L2', 'Policy_Personal L3',\n",
       "       'Policy_Special L1', 'Policy_Special L2', 'Policy_Special L3',\n",
       "       'Renew Offer Type_Offer1', 'Renew Offer Type_Offer2',\n",
       "       'Renew Offer Type_Offer3', 'Renew Offer Type_Offer4',\n",
       "       'Sales Channel_Agent', 'Sales Channel_Branch',\n",
       "       'Sales Channel_Call Center', 'Sales Channel_Web',\n",
       "       'Vehicle Class_Four-Door Car', 'Vehicle Class_Luxury Car',\n",
       "       'Vehicle Class_Luxury SUV', 'Vehicle Class_SUV',\n",
       "       'Vehicle Class_Sports Car', 'Vehicle Class_Two-Door Car',\n",
       "       'Vehicle Size_Large', 'Vehicle Size_Medsize', 'Vehicle Size_Small'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints R2 and RMSE scores\n",
    "def get_score(prediction, lables):    \n",
    "    #print('R2: {}'.format(r2_score(prediction, lables)))\n",
    "    #print('RMSE: {}'.format(np.sqrt(mean_squared_error(prediction, lables))))\n",
    "    return {\n",
    "        'r2' : r2_score(prediction, lables), \n",
    "        'RMSE' : np.sqrt(mean_squared_error(prediction, lables))\n",
    "    }\n",
    "# Shows scores for train and validation sets    \n",
    "def train_test(estimator, x_trn, x_tst, y_trn, y_tst):\n",
    "    prediction_train = estimator.predict(x_trn)\n",
    "    # Printing estimator\n",
    "    #print(estimator)\n",
    "    # Printing train scores\n",
    "    #get_score(prediction_train, y_trn)\n",
    "    prediction_test = estimator.predict(x_tst)\n",
    "    # Printing test scores\n",
    "    #print(\"Test\")\n",
    "    #get_score(prediction_test, y_tst)\n",
    "    return {\n",
    "        'r2' : r2_score(prediction_test, y_tst), \n",
    "        'RMSE' : np.sqrt(mean_squared_error(prediction_test, y_tst))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9ae0ae2b02c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGBoost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'huber'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGBoost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "GBoost = ensemble.GradientBoostingRegressor(n_estimators=10, learning_rate=1, max_depth=3, max_features='sqrt', min_samples_leaf=15, min_samples_split=20, loss='huber').fit(X_train, y_train)\n",
    "train_test(GBoost, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin,tpe,hp, STATUS_OK\n",
    "def f(space):\n",
    "    \n",
    "    global nest, lr, m_d\n",
    "    nest = space['nest']\n",
    "    lr = space['lr']\n",
    "    m_d = space['m_d']\n",
    "    \n",
    "    GBoost = ensemble.GradientBoostingRegressor(n_estimators=nest, learning_rate=lt, max_depth=m_d, max_features='sqrt', min_samples_leaf=15, min_samples_split=20, loss='huber').fit(X_train, y_train)\n",
    "    train_test(GBoost, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    error_train=mean_squared_error(y_test,y_pred)\n",
    "    if (error_train < mse):\n",
    "        mse = error_train\n",
    "        best_look_back = look_back\n",
    "        best_look_front = look_front\n",
    "        best_interval = interval\n",
    "        best_i = i\n",
    "    \n",
    "    return {'loss': error_train, 'status': STATUS_OK }\n",
    "\n",
    "space = {\n",
    "    'nest': hp.quniform('nest', 1000, 11000,1000),\n",
    "    'lr': hp.quniform('lr',0.01,0.5,0.01),\n",
    "    'm_d': hp.quniform('i',5,50,5)\n",
    "    }\n",
    "\n",
    "best = fmin(fn=f,space=space,algo=tpe.suggest,max_evals=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBest = ensemble.GradientBoostingRegressor(n_estimators=10000, learning_rate=0.05, max_depth=15, max_features='sqrt',\n",
    "                                               min_samples_leaf=15, min_samples_split=20, loss='huber').fit(X_train, y_train)\n",
    "\n",
    "train_test(GBest, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
